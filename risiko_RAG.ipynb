{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkWuR1ElP7_v"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Francesco9932/rag_risiko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcJY0q58P7_w"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q torch\n",
        "!pip install -q transformers\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q faiss-cpu\n",
        "\n",
        "!pip install accelerate\n",
        "!pip install -q pypdf\n",
        "!pip install -q spacy\n",
        "!python3 -m spacy download it_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_bz6zmp5P7_x"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j_92HWy1P7_x"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"./rag_risiko/Regolamento-Risiko.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pfpf7SJaP7_y",
        "outputId": "bbf7c1d1-7877-43f3-e892-653998d655ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Il gioco strategico\\nper la conquista\\ndel mondo\\nDa 3 a 6 giocatori\\nEtà: da 10 anni in su\\n2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "pages[1].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bSk6gI2QP7_y"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter()\n",
        "docs = splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhccKrBOP7_y",
        "outputId": "e8d20f79-4d2b-4f7b-d2d2-82c7293982f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='3SCOPO DEL GIOCO\\nRaggiungere per primi il proprio obiettivo segreto.\\nCOMPONENTI\\nUn piano di gioco, rappresentante un planisfero suddiviso \\nin 42 territori, appartenenti ai 6 continenti. Su ogni \\nterritorio è indicato un Punteggio Vittoria. Tale valore \\nserve esclusivamente se decidete di utilizzare le nuove \\nregole per il gioco a tempo ridotto.\\n6 armate di diverso colore composte da piccoli carrarmati \\n(del valore di un’armata ciascuno) e bandierine (del valore \\ndi 10 armate) 3 dadi di colore rosso e 3 dadi di colore blu.\\nUn mazzo di carte “Territori” così suddiviso:\\n•\\t42\\tcarte\\traffiguranti\\t ciascuna\\t uno\\tdei\\tterritori \\n presenti sulla plancia di gioco e il simbolo di una \\n delle tre armi dell’esercito (fante, cavallo, cannone).\\n•\\t2\\tcarte\\t“Jolly”\\tdistinguibili\\t dalle\\taltre\\tper\\tla\\tpresenza \\n dei simboli di tutte le armi e l’assenza della mappa.\\nUn mazzo di carte “Obiettivi”, indicanti gli obiettivi segreti \\nche i giocatori dovranno tentare di raggiungere.', metadata={'source': './rag_risiko/Regolamento-Risiko.pdf', 'page': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "docs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKn8STRFP7_y",
        "outputId": "237d5cf0-d48e-4cd3-f1b6-298a2081bdd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the pre-trained model you want to use\n",
        "modelPath = \"nickprock/sentence-bert-base-italian-uncased\"\n",
        "\n",
        "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
        "# use cpu or gpu\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_kwargs = {'device': device}\n",
        "\n",
        "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "\n",
        "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=modelPath,     # Provide the pre-trained model's path\n",
        "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
        "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "geeOrqD_RYFi"
      },
      "outputs": [],
      "source": [
        "db = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(\n",
        "    pipeline=pipeline,\n",
        "    )"
      ],
      "metadata": {
        "id": "Xzqw9EFxM-bu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# template=\"\"\"\n",
        "#\n",
        "#\n",
        "#                             \\n\\n\\nPlayer Question:\\n{input}\"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "[INST] <>\n",
        "You are an expert board game player and teacher. You have memorized all the rules to every board game ever made.\n",
        "Use the rules in your memory along with any other context you have to answer the players questions below.\n",
        "<>\n",
        "\n",
        "{context}\n",
        "\n",
        "{question} [/INST]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M-9ROwMmVGHL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"input\"])\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")"
      ],
      "metadata": {
        "id": "VLf8cN47WYk1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"Quanti sono i territori? Dammi una risposta coincisa con solo il numero di territori.\"\n",
        "result_ = qa_chain(\n",
        "    input\n",
        ")\n",
        "result = result_[\"result\"].strip()\n",
        "\n",
        "\n",
        "print(input)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "9Ri-BUqJWuA2",
        "outputId": "db38b1af-fe7c-4f17-d250-fc0c4ef094a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quanti sono i territori? Dammi una risposta coincisa con solo il numero di territori.\n",
            "There are 42 territories on the game board.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"Riassumi lo scopo del gioco, specificandone i punti chiave e numero massimo di giocatori. Devi essere coinciso\"\n",
        "result_ = qa_chain(\n",
        "    input\n",
        ")\n",
        "result = result_[\"result\"].strip()\n",
        "\n",
        "\n",
        "print(input)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "kTz75bQlZQnA",
        "outputId": "d2614557-13b8-4079-fe2e-3c6dc5d1a2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Riassumi lo scopo del gioco, specificandone i punti chiave e numero massimo di giocatori. Devi essere coinciso\n",
            "The objective of the game is for each player to reach their own secret goal first. The game components include a game board representing a world map divided into 42 territories belonging to six continents, each territory having a victory point value that serves only if the new rules for reduced time play are used. There are six armies of different colors, each consisting of small infantry units (worth one army each) and banners (worth 10 armies). There are three red dice and three blue dice. There is also a deck of \"Territory\" cards, which depict each territory on the game board and the symbol of one of the three weapons of war. Additionally, there are two \"Jolly\" cards, which are distinguishable from other cards by the presence of symbols of all three weapons and the absence of a map. Finally, there is a deck of \"Objective\" cards, which indicate the secret goals that the players must try to achieve.\n",
            "\n",
            "The game begins with each player completing their initial occupation of the territories they receive randomly. After this, players take turns placing three armies on the game board, using their initial supply, to reinforce their territories. Players are free to position these three armies as they wish, even dividing them among multiple territories. This operation continues until all players' initial supplies are exhausted, at which point during the final round, fewer than three armies can be placed. Once this phase is complete, the dealer reshuffles the cards and adds the two \"Jolly\" cards to the deck, mixes it together, and places it face down within reach.\n",
            "\n",
            "Each player's turn consists of three phases: Rinforzi, Attacco, and Defesa. In the Rinforzi phase, each player takes the number of armies equal to the number of territories they control divided by three (rounded down if necessary). For example, if a player controls 14 territories, they get to take four armies (14 divided by 3 equals 4.6, rounded down to 4). During the Attacco phase, players attack neighboring territories occupied by other players, capturing them if they have more armies than the defending player. If the attacking player loses more armies than the defending player, they lose the battle and retreat. During the Defesa phase, players defend their territories against attacks from other players. They can use their armies to reinforce their territories or to defend against attacks.\n",
            "\n",
            "The game ends when a player reaches their secret goal, or when all players have been eliminated. The winner is the player who reached their secret goal first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AneEqcu3SEQP",
        "outputId": "b1f37947-7afb-4a98-da1f-4ab23cf319c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at mrm8488/bert-italian-finedtuned-squadv1-it-alfa were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# # Questa parte da rivedere:\n",
        "\n",
        "# # Specify the model name you want to use\n",
        "# model_name = \"mrm8488/bert-italian-finedtuned-squadv1-it-alfa\"\n",
        "\n",
        "# # Load the tokenizer associated with the specified model\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# # Define a question-answering pipeline using the model and tokenizer\n",
        "# question_answerer = pipeline(\n",
        "#     \"question-answering\",\n",
        "#     model=model_name,\n",
        "#     tokenizer=tokenizer,\n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "# # Create an instance of the HuggingFacePipeline, which wraps the question-answering pipeline\n",
        "# # with additional model-specific arguments (temperature and max_length)\n",
        "# llm = HuggingFacePipeline(\n",
        "#     pipeline=question_answerer\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKv13IrrSNLy"
      },
      "outputs": [],
      "source": [
        "# # Create a retriever object from the 'db' with a search configuration where it retrieves up to 4 relevant splits/documents.\n",
        "# retriever = db.as_retriever()\n",
        "\n",
        "# # Create a question-answering instance (qa) using the RetrievalQA class.\n",
        "# # It's configured with a language model (llm), a chain type \"refine,\" the retriever we created, and an option to not return source documents.\n",
        "# qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever, return_source_documents=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L21IAagISQu-"
      },
      "outputs": [],
      "source": [
        "# question = \"quanti sono i territori?\"\n",
        "# result = qa.run({\"query\": question})\n",
        "# print(result[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}